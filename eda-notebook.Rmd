---
title: "EDA Notebook: Backpack Price Prediction (S5E2)"
author: "DATA PACKER"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    theme: flatly
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(ggplot2)
library(dplyr)
library(corrplot)
library(GGally)
library(forcats)
library(tidyr)
library(lightgbm)
```

# Introduction

This notebook presents the exploratory data analysis (EDA) for the Kaggle Playground Series - Season 5 Episode 2 (S5E2), which aims to predict backpack prices based on product attributes.

# Load Data

```{r load-data}
# Read the training and test datasets
train <- read.csv("train.csv")
test <- read.csv("test.csv")
```

# Dataset Overview

```{r overview}
# Check the structure of the training data
str(train)

# Summary statistics for the target variable
summary(train$Price)

# Check for missing values in all columns
colSums(is.na(train))

```

# Price Distribution

```{r price-distribution}
# Plot the distribution of backpack prices
hist(train$Price,
     breaks = 50,
     main = "Distribution of Backpack Prices",
     xlab = "Price")
# Log-transformed price distribution
hist(log1p(train$Price),
     breaks = 50,
     col = "gray",
     main = "Log-Transformed Distribution of Backpack Prices",
     xlab = "Log(1 + Price)")


```

# Capacity vs. Price

```{r capacity-vs-price}
# Sample a subset for clearer visualization
set.seed(42)
train_sample <- train[sample(nrow(train), 5000), ]

ggplot(train_sample, aes(x = `Weight.Capacity..kg.`, y = Price)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  ggtitle("Weight Capacity vs. Price (Sampled 5k)")


```
# Numeric Features vs. Price
```{r}
numeric_cols <- train %>% select(where(is.numeric))

# Calculate correlation with Price
correlations <- cor(numeric_cols, use = "complete.obs")["Price",]
correlations <- sort(correlations[-which(names(correlations) == "Price")], decreasing = TRUE)

# Visualize
cor_df <- data.frame(Feature = names(correlations), Correlation = correlations)
ggplot(cor_df, aes(x = Correlation, y = fct_reorder(Feature, Correlation))) +
  geom_col(fill = "lightblue") +
  labs(title = "Correlation of Numerical Features with Price",
       x = "Correlation with Price", y = "Feature") +
  theme_minimal()

```
# Categorical Feature: Brand Frequency
```{r Categorical Feature: Brand Frequency}
# Top 20 most frequent brands
brand_count <- train %>%
  group_by(Brand) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  head(20)

ggplot(brand_count, aes(x = reorder(Brand, -count), y = count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Top 20 Most Frequent Brands", x = "Brand", y = "Count")

```
# Capacity vs. Price
```{r Capacity vs. Price}
# Sample a subset for clearer visualization
set.seed(42)
train_sample <- train[sample(nrow(train), 5000), ]

ggplot(train_sample, aes(x = Weight.Capacity..kg., y = Price)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  ggtitle("Weight Capacity vs. Price (Sampled 5k)")

```
# Brand vs. Price

```{r brand-vs-price}
# Boxplot: Brand vs. Price
ggplot(train, aes(x = Brand, y = Price)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Brand vs. Price")
```


# Material vs. Price

```{r material-vs-price}
# Boxplot: Material vs. Price
ggplot(train, aes(x = Material, y = Price)) +
  geom_boxplot() +
  ggtitle("Material vs. Price")
```

# Laptop Compartment vs. Price

```{r laptop-vs-price}
# Boxplot: Laptop.Compartment vs. Price
ggplot(train, aes(x = Laptop.Compartment, y = Price)) +
  geom_boxplot() +
  ggtitle("Laptop Compartment vs. Price")

```


# Interaction Analysis(Brand × Material,Material × Laptop Compartment )

```{r Interaction Analysis}
train$Brand_Material <- paste(train$Brand, train$Material, sep = "_")
top_combo <- train %>% 
  group_by(Brand_Material) %>%
  summarise(count = n()) %>%
  arrange(desc(count))

ggplot(head(top_combo, 20), aes(x = reorder(Brand_Material, count), y = count)) +
  geom_bar(stat = "identity", fill = "lightgreen") +
  coord_flip() +
  labs(title = "Top 20 Brand × Material Combinations", x = "Brand_Material", y = "Count")

set.seed(42)
sampled <- train %>% sample_n(5000)
ggplot(sampled, aes(x = Weight.Capacity..kg., y = Price, color = Brand)) +
  geom_point(alpha = 0.5) +
  theme(legend.position = "none") +
  labs(title = "Weight Capacity vs Price Colored by Brand")
train$Brand_WeightCombo <- paste(train$Brand, round(train$Weight.Capacity..kg.), sep = "_")
train$Material_Laptop <- paste(train$Material, train$Laptop.Compartment, sep = "_")

material_laptop_price <- train %>%
  group_by(Material_Laptop) %>%
  summarise(mean_price = mean(Price, na.rm = TRUE)) %>%
  arrange(desc(mean_price))

ggplot(head(material_laptop_price, 20), aes(x = reorder(Material_Laptop, mean_price), y = mean_price)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  coord_flip() +
  labs(title = "Top 20 Material × LaptopFeature Importance Avg Prices", x = "Material × Laptop Compartment", y = "Average Price")


# Compartment importance within same brand
sub_train <- train %>% filter(Brand == "Jansport")

ggplot(sub_train, aes(x = Weight.Capacity..kg., y = Price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", color = "blue") +
  labs(title = "Within Jansport: Weight Capacity vs Price")

ggplot(sub_train, aes(x = Compartments, y = Price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Within Jansport: Compartments vs Price")


```
the trend lines (blue and red) are almost horizontal with no apparent slope, the correlation is very weak.

# Feature Importance

```{r Feature Importance}
train_model <- train %>%
  select(Compartments, `Weight.Capacity..kg.`, Brand, Material, Size, Laptop.Compartment, Waterproof, Style, Color, Price) %>%
  na.omit() 

X <- model.matrix(Price ~ . -1, data = train_model)
y <- train_model$Price

# set para
dtrain <- lgb.Dataset(data = X, label = y)
params <- list(objective = "regression", metric = "rmse")
model <- lgb.train(params, dtrain, nrounds = 100)

importance <- lgb.importance(model)
print(importance)
lgb.plot.importance(importance, top_n = 20)

```
# Next Steps

Based on the exploratory analysis, the following steps are planned for the modeling phase:

1. **Feature Engineering**:
   - Encode categorical variables such as `Brand`, `Material`, `Size`, `Style` using one-hot encoding or target encoding.
   - Convert binary variables (e.g., `Waterproof`, `Laptop.Compartment`) into logical/numeric format.
   - Consider interaction terms or grouped features if needed.

2. **Model Selection**:
   - Start with baseline models such as Linear Regression and Decision Tree Regressor.
   - Move to ensemble methods like Random Forest and Gradient Boosting (e.g., XGBoost or LightGBM).

3. **Data Splitting and Evaluation**:
   - Create a validation set or use cross-validation (e.g., 5-fold CV).
   - Evaluate models based on RMSE, as required by the competition metric.

4. **Hyperparameter Tuning**:
   - Use grid search or randomized search to optimize key model parameters.

5. **Final Submission**:
   - Generate predictions on the `test.csv` and submit to Kaggle.
   - Track performance on the public leaderboard and adjust strategies accordingly.

These steps will be iteratively refined based on validation results and model diagnostics.

